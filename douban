import requests
from bs4 import BeautifulSoup

headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36'
}

def URL_list():
    urls = []
    #根据我们观察到的规律进行构建
    for i in range(0,250,25):
        url = 'https://movie.douban.com/top250?start=' + str(i) + '&filter='
        urls.append(url)
    return urls

def get_data(url):
    res = requests.get(url, headers = headers)#发起请求
    soup = BeautifulSoup(res.text,'lxml')#使用BeautifulSoup的解析库解析
    return soup

def parse_data(soup,data):
    target = soup.select("#content > div > div.article > ol > li > div > div.info > div.hd > a > span:nth-of-type(1)")#电影名称
    for i in target:
        data.append(i.get_text())
    return data

def main():
    urls = URL_list()
    data = []
    for url in urls:
        soup = get_data(url)#发起请求
        parse_data(soup,data)#解析数据并存进data列表中
    print("-----  豆瓣前250电影  -----")
    for i in range(len(data)):
        print("%6s"%str(i+1) + "    " +"%25s"%data[i])#格式化输出

main()
